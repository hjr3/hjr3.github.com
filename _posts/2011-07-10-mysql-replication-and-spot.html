---
layout: post
title: mysql replication and spot
tags: []
status: draft
type: post
published: false
meta:
  _edit_last: '1'
---
Master/slave replication is such an easy and common approach to  scaling  database throughput that many systems designers will hardly  consider how  that decision affects SPOT. It is possible for the slave  to not be consistent with the master database. The slave might be  lagging behind the master database. In fact, it is a guarantee that the  slave is lagging behind the master database. Most applications are  perfectly fine with a replication lag of less than 1 second. Even with  replication lag of less than 1 second, the system is now more complex.  Consider the fact that most object-relational model frameworks execute a  select query immediately after the insert query. This is done to get  the auto-incremented primary key value. If the architecture is naive  enough to send all insert statements to the master database and all  select statements to the slave database, the newly inserted row may not  be on the slave database by the time the select statement is executed.

Another problem with data consistency in master/slave replication is  that a table on master may not be identical to the table on the slave.  If the replication is statement based and someone uses a  non-deterministic query, the results of the query on the master and the  slave may be different. A non-deterministic query is one that does not  give the same results twice. This is more common than you think.  Consider the fact that developers like to use NOW() or have table column  defaults of current timestamp. If replication lags behind for a few  seconds during your peak traffic point, you now have inconsistent data.  The system is now more complex as the developers must specify the  timestamp in the application so it is always consistent. The data  consistency also needs to be periodically checked using tools like  maatkit to make sure all tables are in fact identical.

The point I am trying to drive home is that real world applications  duplicate data all the time.Â  Caching data beneath the presentation  layer is much the same way. There are tons of blog articles that will  walk a developers through caching a database results in memcache in less  than 15 minutes. Considering all the consequences of using memcache may  take much longer than 15 minutes to discuss. One of the things I did as  a software architect at HauteLook was to implement the proxy pattern  for caching model results. This kept boilerplate code out of the model  and reduced the complexity of development. I also make sure monitoring  is setup for any cronjob that precomputes memcache data. This allows the  team to make an informed decision on how to proceed, very similar to  the decisions we would have to make if half the slaves are taken out of  the pool because they are inconsistent.
